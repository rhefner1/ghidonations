{"ts":1374673569764,"silentsave":true,"restoring":false,"patch":[[{"diffs":[[1,"# App Engine platform\nimport logging, csv, gc\nfrom google.appengine.ext import blobstore\nfrom google.appengine.api import files, memcache, taskqueue\n\n# Application files\nimport DataModels as models\nimport GlobalUtilities as tools\n\n# Pipeline API\nimport pipeline\nfrom pipeline import common\n\nclass GenerateReport(pipeline.Pipeline):\n\tdef run(self, settings_key, mode, job_id):\n\t\ts = tools.getKey(settings_key).get()\n\n\t\tif mode == \"contacts\":\n\t\t\tquery = s.data.all_contacts\n\t\t\tnum_results = 30\n\n\t\telif mode == \"donations\":\n\t\t\tquery = s.data.all_donations\n\t\t\tnum_results = 50\n\n\t\telif mode == \"individuals\":\n\t\t\tquery = s.data.all_individuals\n\t\t\tnum_results = 15\n\n\t\telse:\n\t\t\traise Exception(\"Unidentified mode in GenerateReport\")\n\t\t\n\t\tblobs = []\n\t\tcursor = None\n\n\t\t# Create header CSV file\n\t\theader_file_name = job_id + \"-0.csv\"\n\t\tblobs.append( (yield HeaderCSV(mode, header_file_name)) )\n\n\t\twhile True:\n\t\t\tresults = tools.queryCursorDB(query, cursor, keys_only=True, num_results=num_results)\n\t\t\tkeys, cursor = results[0], results[1]\n\t\t\tfile_name = job_id + \"-\" + str( len(blobs) ) + \".csv\"\n\n\t\t\tkeys = tools.ndbKeyToUrlsafe(keys)\n\n\t\t\tblobs.append( (yield CreateCSV(mode, file_name, keys)) )\n\n\t\t\tif cursor == None:\n\t\t\t\tbreak\n\n\t\tfinal_file_name = s.name + \"-\" + mode.title() + \".csv\"\n\t\tfinal_blob = yield ConcatCSV(job_id, final_file_name, *blobs)\n\t\tyield ConfirmCompletion(job_id, final_blob)\n\nclass HeaderCSV(pipeline.Pipeline):\n\tdef run(self, mode, file_name):\n\t\tfile_key = tools.newFile(\"text/csv\", file_name)\n\n\t\twith files.open(file_key, 'a') as f:\n\t\t\twriter = csv.writer(f)\n\n\t\t\t# Write headers\n\t\t\theader_data = []\n\n\t\t\tif mode == \"contacts\":\n\t\t\t\theader_data.append(\"Name\")\n\t\t\t\theader_data.append(\"Email\")\n\t\t\t\theader_data.append(\"Total Donated\")\n\t\t\t\theader_data.append(\"Number Donations\")\n\t\t\t\theader_data.append(\"Phone\")\n\t\t\t\theader_data.append(\"Street\")\n\t\t\t\theader_data.append(\"City\")\n\t\t\t\theader_data.append(\"State\")\n\t\t\t\theader_data.append(\"Zipcode\")\n\t\t\t\theader_data.append(\"Created\")\n\n\t\t\tif mode == \"donations\":\n\t\t\t\theader_data.append(\"Date\")\n\t\t\t\theader_data.append(\"Name\")\n\t\t\t\theader_data.append(\"Email\")\n\t\t\t\theader_data.append(\"Amount Donated\")\n\t\t\t\theader_data.append(\"Payment Type\")\n\t\t\t\theader_data.append(\"Team\")\n\t\t\t\theader_data.append(\"Individual\")\n\t\t\t\theader_data.append(\"Reviewed\")\n\n\t\t\telif mode == \"individuals\":\n\t\t\t\theader_data.append(\"Name\")\n\t\t\t\theader_data.append(\"Email\")\n\t\t\t\theader_data.append(\"Teams\")\n\t\t\t\theader_data.append(\"Raised\")\n\t\t\t\theader_data.append(\"Date Created\")\n\n\t\t\twriter.writerow(header_data)\n\n\t\tfiles.finalize(file_key)\n\t\tblob_key = str(files.blobstore.get_blob_key(file_key))\n\n\t\ttaskqueue.add(url=\"/tasks/deletespreadsheet\", params={'k':blob_key}, countdown=3600, queue_name=\"deletespreadsheet\")\n\n\t\treturn blob_key\n\nclass CreateCSV(pipeline.Pipeline):\n\tdef run(self, mode, file_name, keys):\n\t\tfile_key = tools.newFile(\"text/csv\", file_name)\n\n\t\twith files.open(file_key, 'a') as f:\n\t\t\twriter = csv.writer(f)\n\n\t\t\tfor k in keys:\n\t\t\t\ttry:\n\t\t\t\t\te = tools.getKey(k).get()\n\n\t\t\t\t\trow_data = []\n\n\t\t\t\t\tif mode == \"contacts\":\n\t\t\t\t\t\tc = e\n\t\t\t\t\t\trow_data.append(c.name)\n\t\t\t\t\t\trow_data.append(c.email)\n\t\t\t\t\t\trow_data.append(c.data.donation_total)\n\t\t\t\t\t\trow_data.append(c.data.number_donations)\n\t\t\t\t\t\trow_data.append(c.phone)\n\t\t\t\t\t\trow_data.append(c.address[0])\n\t\t\t\t\t\trow_data.append(c.address[1])\n\t\t\t\t\t\trow_data.append(c.address[2])\n\t\t\t\t\t\trow_data.append(c.address[3])\n\t\t\t\t\t\trow_data.append(str(c.creation_date))\n\n\t\t\t\t\telif mode == \"donations\":\n\t\t\t\t\t\td = e\n\t\t\t\t\t\trow_data.append(str(d.donation_date))\n\t\t\t\t\t\trow_data.append(d.name)\n\t\t\t\t\t\trow_data.append(d.email)\n\t\t\t\t\t\trow_data.append(str(d.amount_donated))\n\t\t\t\t\t\trow_data.append(d.payment_type)\n\t\t\t\t\t\trow_data.append(d.designated_team)\n\t\t\t\t\t\trow_data.append(d.designated_individual)\n\t\t\t\t\t\trow_data.append(str(d.reviewed))\n\n\t\t\t\t\telif mode == \"individuals\":\n\t\t\t\t\t\ti = e\n\t\t\t\t\t\trow_data.append(i.name)\n\t\t\t\t\t\trow_data.append(i.email)\n\t\t\t\t\t\trow_data.append(i.data.readable_team_names)\n\t\t\t\t\t\trow_data.append(str(i.data.donation_total))\n\t\t\t\t\t\trow_data.append(str(i.creation_date))\n\n\t\t\t\t\twriter.writerow(row_data)\n\n\t\t\t\texcept Exception, e:\n\t\t\t\t\tlogging.error(\"Failed on key \" + k + \" because \" + str(e))\n\n\t\t\t\t# Call the garbage handler\n\t\t\t\tgc.collect()\n\n\t\tfiles.finalize(file_key)\n\t\tblob_key = str(files.blobstore.get_blob_key(file_key))\n\n\t\ttaskqueue.add(url=\"/tasks/deletespreadsheet\", params={'k':blob_key}, countdown=3600, queue_name=\"deletespreadsheet\")\n\n\t\treturn blob_key\n\t\t\nclass ConcatCSV(pipeline.Pipeline):\n\tdef run(self, job_id, file_name, *blobs):\n\t\tfile_key = tools.newFile(\"text/csv\", file_name)\n\n\t\twith files.open(file_key, 'a') as f:\n\n\t\t\tfor b in blobs:\n\t\t\t\tblob_reader = blobstore.BlobReader(b)\n\t\t\t\tvalue = blob_reader.read()\n\n\t\t\t\tf.write(value)\n\n\t\t\t\t# Call the garbage handler\n\t\t\t\tgc.collect()\n\n\t\tfiles.finalize(file_key)\n\t\tblob_key = str(files.blobstore.get_blob_key(file_key))\n\n\t\ttaskqueue.add(url=\"/tasks/deletespreadsheet\", params={'k':blob_key}, countdown=3600, queue_name=\"deletespreadsheet\")\n\n\t\treturn blob_key\n\nclass ConfirmCompletion(pipeline.Pipeline):\n\tdef run(self, job_id, final_blob):\n\t\tmemcache.set(job_id, final_blob)"]],"start1":0,"start2":0,"length1":0,"length2":5105}]],"length":5105}
